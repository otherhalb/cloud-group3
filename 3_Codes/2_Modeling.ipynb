{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b132a1-1bf1-4a79-b9df-dd2935978c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/appendicitis_project/modeling/venv/lib64/python3.9/site-packages/boto3/compat.py:84: PythonDeprecationWarning: Boto3 will no longer support Python 3.9 starting April 29, 2026. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.10 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "bucket = \"group3-appendicitis-bucket\"\n",
    "prefix = \"data\"  \n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "def read_csv_from_s3(key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    return pd.read_csv(obj[\"Body\"])\n",
    "\n",
    "X = read_csv_from_s3(\"data/X_clean.csv\")\n",
    "y_df = read_csv_from_s3(\"data/y_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d06f9de-955e-44cb-8360-2b828c081f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff2774-6a0c-4e7a-8d86-7526c546b12b",
   "metadata": {},
   "source": [
    "#### Prepare the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08864fad-35c5-4089-8e47-5d04e63d85c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value counts (0 = no appendicitis, 1 = appendicitis):\n",
      "Diagnosis\n",
      "1    463\n",
      "0    317\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_df = y_df.copy()\n",
    "y_df[\"Diagnosis\"] = (\n",
    "    y_df[\"Diagnosis\"]\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .map({\"appendicitis\": 1, \"no appendicitis\": 0})\n",
    ")\n",
    "\n",
    "y = y_df[[\"Diagnosis\"]]\n",
    "\n",
    "print(\"Target value counts (0 = no appendicitis, 1 = appendicitis):\")\n",
    "print(y[\"Diagnosis\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81977e-ad9a-412e-bc43-05efccd2d2af",
   "metadata": {},
   "source": [
    "#### Train, Validation and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea66f9a-6a23-417b-ae3b-19ab5cdd5483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (X_train, X_val, X_test): (468, 53) (156, 53) (156, 53)\n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    train_size=0.6,\n",
    "    stratify=y[\"Diagnosis\"],\n",
    "    random_state=random_seed\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    train_size=0.5,\n",
    "    stratify=y_temp[\"Diagnosis\"],\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val   = X_val.reset_index(drop=True)\n",
    "X_test  = X_test.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val   = y_val.reset_index(drop=True)\n",
    "y_test  = y_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Shapes (X_train, X_val, X_test):\", X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761dccc-24a6-4ad6-b005-4ee31e7d35a3",
   "metadata": {},
   "source": [
    "#### Checking variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d330c85f-4596-4135-a081-edc5e47fdaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common variables across train/val/test:\n",
      "                          common var\n",
      "0                   Abscess_Location\n",
      "1                                Age\n",
      "2                     Alvarado_Score\n",
      "3                      Appendicolith\n",
      "4               Appendicular_Abscess\n",
      "5                  Appendix_Diameter\n",
      "6               Appendix_Wall_Layers\n",
      "7                     Appendix_on_US\n",
      "8                                BMI\n",
      "9                   Body_Temperature\n",
      "10             Bowel_Wall_Thickening\n",
      "11                               CRP\n",
      "12       Conglomerate_of_Bowel_Loops\n",
      "13  Contralateral_Rebound_Tenderness\n",
      "14                       Coprostasis\n",
      "15                     Coughing_Pain\n",
      "16                         Diagnosis\n",
      "17                           Dysuria\n",
      "18                         Enteritis\n",
      "19                       Free_Fluids\n",
      "20            Gynecological_Findings\n",
      "21                            Height\n",
      "22                        Hemoglobin\n",
      "23                             Ileus\n",
      "24    Ipsilateral_Rebound_Tenderness\n",
      "25                  Ketones_in_Urine\n",
      "26                    Length_of_Stay\n",
      "27                  Loss_of_Appetite\n",
      "28              Lower_Right_Abd_Pain\n",
      "29              Lymph_Nodes_Location\n",
      "30                         Meteorism\n",
      "31                    Migratory_Pain\n",
      "32                            Nausea\n",
      "33             Neutrophil_Percentage\n",
      "34                      Neutrophilia\n",
      "35     Paedriatic_Appendicitis_Score\n",
      "36          Pathological_Lymph_Nodes\n",
      "37                       Perforation\n",
      "38                         Perfusion\n",
      "39                       Peritonitis\n",
      "40                        Psoas_Sign\n",
      "41                         RBC_Count\n",
      "42                      RBC_in_Urine\n",
      "43                               RDW\n",
      "44             Segmented_Neutrophils\n",
      "45                               Sex\n",
      "46                             Stool\n",
      "47       Surrounding_Tissue_Reaction\n",
      "48                       Target_Sign\n",
      "49                 Thrombocyte_Count\n",
      "50                      US_Performed\n",
      "51                         WBC_Count\n",
      "52                      WBC_in_Urine\n",
      "53                            Weight\n"
     ]
    }
   ],
   "source": [
    "def common_var_checker(df_train, df_val, df_test, target):\n",
    "    \"\"\"\n",
    "    The common variables checker\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train : the dataframe of training data\n",
    "    df_val   : the dataframe of validation data\n",
    "    df_test  : the dataframe of test data\n",
    "    target   : the name of the target\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame of common variables between train, val and test\n",
    "    \"\"\"\n",
    "    df_common_var = pd.DataFrame(\n",
    "        np.intersect1d(\n",
    "            np.intersect1d(df_train.columns, df_val.columns),\n",
    "            np.union1d(df_test.columns, [target])\n",
    "        ),\n",
    "        columns=[\"common var\"]\n",
    "    )\n",
    "    return df_common_var\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val   = pd.concat([X_val, y_val], axis=1)\n",
    "df_test  = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "target = \"Diagnosis\"\n",
    "df_common_var = common_var_checker(df_train, df_val, df_test, target)\n",
    "print(\"\\nCommon variables across train/val/test:\")\n",
    "print(df_common_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd8138-2d21-4f4f-bdbc-50c13c7dc5f6",
   "metadata": {},
   "source": [
    "#### Removing features with >50% missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ccb60b-9f1f-47dc-9ae3-220dccf41b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features with >50% missing data:\n",
      "Index(['Segmented_Neutrophils', 'Appendix_Wall_Layers', 'Target_Sign',\n",
      "       'Appendicolith', 'Perfusion', 'Perforation',\n",
      "       'Surrounding_Tissue_Reaction', 'Appendicular_Abscess',\n",
      "       'Abscess_Location', 'Pathological_Lymph_Nodes', 'Lymph_Nodes_Location',\n",
      "       'Bowel_Wall_Thickening', 'Conglomerate_of_Bowel_Loops', 'Ileus',\n",
      "       'Coprostasis', 'Meteorism', 'Enteritis', 'Gynecological_Findings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = X_train.isnull().mean()\n",
    "features_to_remove = missing_percentage[missing_percentage > 0.5].index\n",
    "\n",
    "print(\"\\nFeatures with >50% missing data:\")\n",
    "print(features_to_remove)\n",
    "\n",
    "# Drop those columns from all splits\n",
    "X_train = X_train.drop(columns=features_to_remove)\n",
    "X_val   = X_val.drop(columns=features_to_remove)\n",
    "X_test  = X_test.drop(columns=features_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c6763-05fa-4353-8665-fd6d6cf27b89",
   "metadata": {},
   "source": [
    "#### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52a5e2f-a831-4b7f-8251-75ab090489c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric columns:\n",
      "Index(['Age', 'BMI', 'Height', 'Weight', 'Length_of_Stay', 'Alvarado_Score',\n",
      "       'Paedriatic_Appendicitis_Score', 'Appendix_Diameter',\n",
      "       'Body_Temperature', 'WBC_Count', 'Neutrophil_Percentage', 'RBC_Count',\n",
      "       'Hemoglobin', 'RDW', 'Thrombocyte_Count', 'CRP'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical columns:\n",
      "Index(['Sex', 'Appendix_on_US', 'Migratory_Pain', 'Lower_Right_Abd_Pain',\n",
      "       'Contralateral_Rebound_Tenderness', 'Coughing_Pain', 'Nausea',\n",
      "       'Loss_of_Appetite', 'Neutrophilia', 'Ketones_in_Urine', 'RBC_in_Urine',\n",
      "       'WBC_in_Urine', 'Dysuria', 'Stool', 'Peritonitis', 'Psoas_Sign',\n",
      "       'Ipsilateral_Rebound_Tenderness', 'US_Performed', 'Free_Fluids'],\n",
      "      dtype='object')\n",
      "\n",
      "Remaining numeric NaNs after imputation:\n",
      "Age                              0\n",
      "BMI                              0\n",
      "Height                           0\n",
      "Weight                           0\n",
      "Length_of_Stay                   0\n",
      "Alvarado_Score                   0\n",
      "Paedriatic_Appendicitis_Score    0\n",
      "Appendix_Diameter                0\n",
      "Body_Temperature                 0\n",
      "WBC_Count                        0\n",
      "Neutrophil_Percentage            0\n",
      "RBC_Count                        0\n",
      "Hemoglobin                       0\n",
      "RDW                              0\n",
      "Thrombocyte_Count                0\n",
      "CRP                              0\n",
      "dtype: int64\n",
      "\n",
      "Categorical columns with missing values:\n",
      "RBC_in_Urine                        124\n",
      "Ketones_in_Urine                    118\n",
      "WBC_in_Urine                        117\n",
      "Ipsilateral_Rebound_Tenderness      100\n",
      "Free_Fluids                          43\n",
      "Neutrophilia                         31\n",
      "Psoas_Sign                           23\n",
      "Dysuria                              17\n",
      "Stool                                11\n",
      "Contralateral_Rebound_Tenderness      8\n",
      "Coughing_Pain                         6\n",
      "Peritonitis                           5\n",
      "Migratory_Pain                        5\n",
      "Loss_of_Appetite                      5\n",
      "Lower_Right_Abd_Pain                  4\n",
      "Nausea                                3\n",
      "Appendix_on_US                        2\n",
      "Sex                                   1\n",
      "dtype: int64\n",
      "\n",
      "Remaining categorical NaNs after imputation:\n",
      "Sex                                 0\n",
      "Appendix_on_US                      0\n",
      "Migratory_Pain                      0\n",
      "Lower_Right_Abd_Pain                0\n",
      "Contralateral_Rebound_Tenderness    0\n",
      "Coughing_Pain                       0\n",
      "Nausea                              0\n",
      "Loss_of_Appetite                    0\n",
      "Neutrophilia                        0\n",
      "Ketones_in_Urine                    0\n",
      "RBC_in_Urine                        0\n",
      "WBC_in_Urine                        0\n",
      "Dysuria                             0\n",
      "Stool                               0\n",
      "Peritonitis                         0\n",
      "Psoas_Sign                          0\n",
      "Ipsilateral_Rebound_Tenderness      0\n",
      "US_Performed                        0\n",
      "Free_Fluids                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "numeric_cols = X_train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "print(\"\\nNumeric columns:\")\n",
    "print(numeric_cols)\n",
    "print(\"\\nCategorical columns:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "# Numerical imputation \n",
    "mean_impute_cols = [\n",
    "    \"BMI\", \"Height\", \"Weight\", \"Alvarado_Score\",\n",
    "    \"Paedriatic_Appendicitis_Score\", \"Appendix_Diameter\",\n",
    "    \"WBC_Count\", \"Neutrophil_Percentage\", \"RBC_Count\",\n",
    "    \"Thrombocyte_Count\"\n",
    "]\n",
    "\n",
    "median_impute_cols = [\n",
    "    \"Body_Temperature\",\n",
    "    \"Length_of_Stay\",\n",
    "    \"CRP\",\n",
    "    \"Hemoglobin\",\n",
    "    \"RDW\"\n",
    "]\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train[mean_impute_cols] = mean_imputer.fit_transform(X_train[mean_impute_cols])\n",
    "X_val[mean_impute_cols]   = mean_imputer.transform(X_val[mean_impute_cols])\n",
    "X_test[mean_impute_cols]  = mean_imputer.transform(X_test[mean_impute_cols])\n",
    "\n",
    "median_imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train[median_impute_cols] = median_imputer.fit_transform(X_train[median_impute_cols])\n",
    "X_val[median_impute_cols]   = median_imputer.transform(X_val[median_impute_cols])\n",
    "X_test[median_impute_cols]  = median_imputer.transform(X_test[median_impute_cols])\n",
    "\n",
    "print(\"\\nRemaining numeric NaNs after imputation:\")\n",
    "print(X_train[numeric_cols].isnull().sum())\n",
    "\n",
    "# Categorical imputation \n",
    "cat_missing = X_train[categorical_cols].isnull().sum()\n",
    "cat_missing = cat_missing[cat_missing > 0].sort_values(ascending=False)\n",
    "print(\"\\nCategorical columns with missing values:\")\n",
    "print(cat_missing)\n",
    "\n",
    "categorical_impute_cols = cat_missing.index.tolist()\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "X_train[categorical_impute_cols] = cat_imputer.fit_transform(X_train[categorical_impute_cols])\n",
    "X_val[categorical_impute_cols]   = cat_imputer.transform(X_val[categorical_impute_cols])\n",
    "X_test[categorical_impute_cols]  = cat_imputer.transform(X_test[categorical_impute_cols])\n",
    "\n",
    "print(\"\\nRemaining categorical NaNs after imputation:\")\n",
    "print(X_train[categorical_cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea1734-a844-46f6-ba7e-4a3be89cf0ed",
   "metadata": {},
   "source": [
    "#### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52a8e06b-6295-4004-9482-799d2bcd51f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values for each categorical column:\n",
      "\n",
      "Sex: ['female' 'male']\n",
      "\n",
      "Appendix_on_US: ['yes' 'no']\n",
      "\n",
      "Migratory_Pain: ['yes' 'no']\n",
      "\n",
      "Lower_Right_Abd_Pain: ['yes' 'no']\n",
      "\n",
      "Contralateral_Rebound_Tenderness: ['no' 'yes']\n",
      "\n",
      "Coughing_Pain: ['yes' 'no']\n",
      "\n",
      "Nausea: ['yes' 'no']\n",
      "\n",
      "Loss_of_Appetite: ['no' 'yes']\n",
      "\n",
      "Neutrophilia: ['yes' 'no']\n",
      "\n",
      "Ketones_in_Urine: ['+++' 'no' '++' '+']\n",
      "\n",
      "RBC_in_Urine: ['no' '+' '++' '+++']\n",
      "\n",
      "WBC_in_Urine: ['+' 'no' '++' '+++']\n",
      "\n",
      "Dysuria: ['no' 'yes']\n",
      "\n",
      "Stool: ['diarrhea' 'normal' 'constipation' 'constipation, diarrhea']\n",
      "\n",
      "Peritonitis: ['no' 'local' 'generalized']\n",
      "\n",
      "Psoas_Sign: ['no' 'yes']\n",
      "\n",
      "Ipsilateral_Rebound_Tenderness: ['no' 'yes']\n",
      "\n",
      "US_Performed: ['yes' 'no']\n",
      "\n",
      "Free_Fluids: ['yes' 'no']\n",
      "\n",
      "Nominal columns to one-hot encode:\n",
      "['Free_Fluids', 'Contralateral_Rebound_Tenderness', 'Coughing_Pain', 'Migratory_Pain', 'Loss_of_Appetite', 'Sex', 'Nausea', 'Neutrophilia', 'Appendix_on_US', 'Ipsilateral_Rebound_Tenderness', 'US_Performed', 'Lower_Right_Abd_Pain', 'Dysuria', 'Psoas_Sign']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "print(\"\\nUnique values for each categorical column:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}: {X_train[col].unique()}\")\n",
    "\n",
    "# Ordinal mappings\n",
    "ordinal_mapping = {\n",
    "    \"Peritonitis\": {\"no\": 0, \"local\": 1, \"generalized\": 2},\n",
    "    \"Stool\": {\"normal\": 0, \"constipation\": 1, \"diarrhea\": 2, \"constipation, diarrhea\": 3},\n",
    "    \"Ketones_in_Urine\": {\"no\": 0, \"+\": 1, \"++\": 2, \"+++\": 3},\n",
    "    \"RBC_in_Urine\": {\"no\": 0, \"+\": 1, \"++\": 2, \"+++\": 3},\n",
    "    \"WBC_in_Urine\": {\"no\": 0, \"+\": 1, \"++\": 2, \"+++\": 3}\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_mapping.items():\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = X_train[col].map(mapping)\n",
    "        X_val[col]   = X_val[col].map(mapping)\n",
    "        X_test[col]  = X_test[col].map(mapping)\n",
    "\n",
    "# Recompute categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Nominal (non-ordinal) columns\n",
    "nominal_cols = list(set(categorical_cols) - set(ordinal_mapping.keys()))\n",
    "print(\"\\nNominal columns to one-hot encode:\")\n",
    "print(nominal_cols)\n",
    "\n",
    "# One-hot encode nominal columns\n",
    "X_train = pd.get_dummies(X_train, columns=nominal_cols, drop_first=True)\n",
    "X_val   = pd.get_dummies(X_val, columns=nominal_cols, drop_first=True)\n",
    "X_test  = pd.get_dummies(X_test, columns=nominal_cols, drop_first=True)\n",
    "\n",
    "# Align validation and test columns to training\n",
    "X_val  = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "269eefa8-0cc5-437c-9cb2-dfef8746b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[\"Diagnosis\"]\n",
    "y_val   = y_val[\"Diagnosis\"]\n",
    "y_test  = y_test[\"Diagnosis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d7cc3-4ba1-44bb-a618-29680ad567a7",
   "metadata": {},
   "source": [
    "#### Scaling numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8981b446-a3b8-4cea-bdf7-eda73bf36097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb7cd7-4ba3-4442-8461-03e1716eac97",
   "metadata": {},
   "source": [
    "#### Checking class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b7241b-d003-46ca-8527-d5d9dd27a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class counts in y_train (0=no appendicitis, 1=appendicitis):\n",
      "Diagnosis\n",
      "0    190\n",
      "1    278\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "print(\"\\nClass counts in y_train (0=no appendicitis, 1=appendicitis):\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c788f-4fa3-43da-a467-ff2fc769ae4a",
   "metadata": {},
   "source": [
    "#### Handling class imbalance + models + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45954897-c3cf-4e0d-a8cc-935b8815dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Training model: LR\n",
      "==============================\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "--- Results for LR ---\n",
      "Best Parameters: {'model__C': 1}\n",
      "Best CV f1_macro Score: 0.8884\n",
      "Prediction shape: (156,) | True labels shape: (156,)\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "no appendicitis       0.82      0.94      0.88        64\n",
      "   appendicitis       0.95      0.86      0.90        92\n",
      "\n",
      "       accuracy                           0.89       156\n",
      "      macro avg       0.89      0.90      0.89       156\n",
      "   weighted avg       0.90      0.89      0.89       156\n",
      "\n",
      "\n",
      "==============================\n",
      "Training model: MLPC\n",
      "==============================\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "--- Results for MLPC ---\n",
      "Best Parameters: {'model__activation': 'relu', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant', 'model__solver': 'adam'}\n",
      "Best CV f1_macro Score: 0.8282\n",
      "Prediction shape: (156,) | True labels shape: (156,)\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "no appendicitis       0.80      0.88      0.84        64\n",
      "   appendicitis       0.91      0.85      0.88        92\n",
      "\n",
      "       accuracy                           0.86       156\n",
      "      macro avg       0.85      0.86      0.86       156\n",
      "   weighted avg       0.86      0.86      0.86       156\n",
      "\n",
      "\n",
      "==============================\n",
      "Training model: RFC\n",
      "==============================\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "\n",
      "--- Results for RFC ---\n",
      "Best Parameters: {'model__bootstrap': False, 'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "Best CV f1_macro Score: 0.9424\n",
      "Prediction shape: (156,) | True labels shape: (156,)\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "no appendicitis       0.89      0.92      0.91        64\n",
      "   appendicitis       0.94      0.92      0.93        92\n",
      "\n",
      "       accuracy                           0.92       156\n",
      "      macro avg       0.92      0.92      0.92       156\n",
      "   weighted avg       0.92      0.92      0.92       156\n",
      "\n",
      "\n",
      "==============================\n",
      "Training model: HGBC\n",
      "==============================\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "\n",
      "--- Results for HGBC ---\n",
      "Best Parameters: {'model__learning_rate': 0.5, 'model__max_depth': 5, 'model__max_iter': 100, 'model__min_samples_leaf': 20}\n",
      "Best CV f1_macro Score: 0.9712\n",
      "Prediction shape: (156,) | True labels shape: (156,)\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "no appendicitis       0.95      0.92      0.94        64\n",
      "   appendicitis       0.95      0.97      0.96        92\n",
      "\n",
      "       accuracy                           0.95       156\n",
      "      macro avg       0.95      0.94      0.95       156\n",
      "   weighted avg       0.95      0.95      0.95       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "smote = SMOTE(random_state=random_seed)\n",
    "\n",
    "models = {\n",
    "    \"lr\":   LogisticRegression(class_weight=\"balanced\", random_state=random_seed, max_iter=1000),\n",
    "    \"mlpc\": MLPClassifier(early_stopping=True, random_state=random_seed),\n",
    "    \"rfc\":  RandomForestClassifier(class_weight=\"balanced\", random_state=random_seed),\n",
    "    \"hgbc\": HistGradientBoostingClassifier(random_state=random_seed)\n",
    "}\n",
    "\n",
    "pipes = {acronym: Pipeline([(\"model\", model)]) for acronym, model in models.items()}\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {}\n",
    "\n",
    "param_grids[\"lr\"] = {\n",
    "    \"model__C\": [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "param_grids[\"mlpc\"] = {\n",
    "    \"model__hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "    \"model__activation\": [\"relu\", \"tanh\"],\n",
    "    \"model__solver\": [\"adam\", \"sgd\"],\n",
    "    \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"model__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "}\n",
    "\n",
    "param_grids[\"rfc\"] = {\n",
    "    \"model__n_estimators\": [50, 100, 200],\n",
    "    \"model__max_depth\": [10, 20, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],\n",
    "    \"model__bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "param_grids[\"hgbc\"] = {\n",
    "    \"model__learning_rate\": [0.01, 0.1, 0.5],\n",
    "    \"model__max_iter\": [100, 200],\n",
    "    \"model__max_depth\": [3, 5, 7],\n",
    "    \"model__min_samples_leaf\": [20, 30, 50]\n",
    "}\n",
    "\n",
    "grid_searches = {}\n",
    "model_predictions = {}\n",
    "\n",
    "# Train models with/without SMOTE\n",
    "for acronym, pipe in pipes.items():\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Training model: {acronym.upper()}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    if acronym in [\"mlpc\", \"hgbc\"]:\n",
    "        # Apply SMOTE for models without class_weight\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "        gs = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=param_grids[acronym],\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            scoring=\"f1_macro\",\n",
    "            verbose=1\n",
    "        )\n",
    "        gs.fit(X_train_resampled, y_train_resampled)\n",
    "    else:\n",
    "        \n",
    "        gs = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=param_grids[acronym],\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            scoring=\"f1_macro\",\n",
    "            verbose=1\n",
    "        )\n",
    "        gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "    grid_searches[acronym] = gs\n",
    "\n",
    "    print(f\"\\n--- Results for {acronym.upper()} ---\")\n",
    "    print(\"Best Parameters:\", gs.best_params_)\n",
    "    print(f\"Best CV f1_macro Score: {gs.best_score_:.4f}\")\n",
    "\n",
    "    # Test set performance\n",
    "    y_pred = gs.best_estimator_.predict(X_test_scaled)\n",
    "    model_predictions[acronym] = y_pred\n",
    "\n",
    "    print(f\"Prediction shape: {y_pred.shape} | True labels shape: {y_test.shape}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"no appendicitis\", \"appendicitis\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c4d8c-33de-47b1-9d09-6a9d27428ebf",
   "metadata": {},
   "source": [
    "After completing all preprocessing steps—including handling missing values, ordinal and nominal encoding, feature scaling, and class-imbalance handling—we trained four supervised learning models and evaluated them using cross-validation and hyperparameter tuning. Logistic Regression achieved a strong linear baseline with an f1_macro score of ~0.89 and an overall test accuracy of 0.89, demonstrating that a linear decision boundary captures a meaningful amount of signal in the dataset. The MLPClassifier performed moderately well with an f1_macro of 0.82, although its improvement was limited compared to tree-based models, likely due to the relatively small tabular dataset and the model’s sensitivity to architecture and hyperparameters.\n",
    "\n",
    "The ensemble methods showed the most robust and consistent performance. Random Forest achieved an f1_macro of 0.93 and a test accuracy of 0.94, benefiting from its ability to model nonlinear clinical patterns and interactions. The best overall performance came from the HistGradientBoosting Classifier, which achieved a cross-validated f1_macro of 0.97 and a test accuracy of 0.95 with highly balanced precision and recall across both diagnostic classes. These results indicate that gradient-boosted decision trees are the most effective and reliable approach for predicting appendicitis in this dataset, outperforming both linear and neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70040af-49e9-42a8-b614-d513cbcbed92",
   "metadata": {},
   "source": [
    "#### Auto ML With Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91242ba9-2f5f-46aa-a7b1-42baaa68942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 36) (156, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length_of_Stay</th>\n",
       "      <th>Alvarado_Score</th>\n",
       "      <th>Paedriatic_Appendicitis_Score</th>\n",
       "      <th>Appendix_Diameter</th>\n",
       "      <th>Body_Temperature</th>\n",
       "      <th>WBC_Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Nausea_yes</th>\n",
       "      <th>Neutrophilia_yes</th>\n",
       "      <th>Appendix_on_US_yes</th>\n",
       "      <th>Ipsilateral_Rebound_Tenderness_yes</th>\n",
       "      <th>US_Performed_yes</th>\n",
       "      <th>Lower_Right_Abd_Pain_yes</th>\n",
       "      <th>Dysuria_yes</th>\n",
       "      <th>Psoas_Sign_yes</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.58</td>\n",
       "      <td>22.98</td>\n",
       "      <td>155.0</td>\n",
       "      <td>55.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>38.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.36</td>\n",
       "      <td>13.19</td>\n",
       "      <td>120.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.51</td>\n",
       "      <td>19.03</td>\n",
       "      <td>147.5</td>\n",
       "      <td>41.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.48</td>\n",
       "      <td>18.81</td>\n",
       "      <td>144.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>38.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.27</td>\n",
       "      <td>15.19</td>\n",
       "      <td>152.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age    BMI  Height  Weight  Length_of_Stay  Alvarado_Score  \\\n",
       "0  14.58  22.98   155.0    55.2             4.0             9.0   \n",
       "1   6.36  13.19   120.0    19.0             3.0             8.0   \n",
       "2   9.51  19.03   147.5    41.4             3.0             9.0   \n",
       "3  11.48  18.81   144.0    39.0             9.0             4.0   \n",
       "4  11.27  15.19   152.0    35.1             3.0             6.0   \n",
       "\n",
       "   Paedriatic_Appendicitis_Score  Appendix_Diameter  Body_Temperature  \\\n",
       "0                            9.0                4.6              38.7   \n",
       "1                            6.0                7.0              38.2   \n",
       "2                            6.0                4.5              37.8   \n",
       "3                            3.0                5.1              38.6   \n",
       "4                            7.0                4.7              38.0   \n",
       "\n",
       "   WBC_Count  ...  Sex_male  Nausea_yes  Neutrophilia_yes  Appendix_on_US_yes  \\\n",
       "0       14.0  ...     False        True              True                True   \n",
       "1       20.9  ...     False       False              True                True   \n",
       "2       12.4  ...      True        True              True                True   \n",
       "3        4.4  ...     False       False             False                True   \n",
       "4        8.7  ...     False        True             False                True   \n",
       "\n",
       "   Ipsilateral_Rebound_Tenderness_yes  US_Performed_yes  \\\n",
       "0                               False              True   \n",
       "1                               False              True   \n",
       "2                               False              True   \n",
       "3                               False              True   \n",
       "4                               False              True   \n",
       "\n",
       "   Lower_Right_Abd_Pain_yes  Dysuria_yes  Psoas_Sign_yes  Diagnosis  \n",
       "0                      True        False           False          0  \n",
       "1                      True        False           False          1  \n",
       "2                      True        False           False          0  \n",
       "3                      True        False           False          1  \n",
       "4                      True        False           False          0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import setup, compare_models, pull, save_model, predict_model\n",
    "df_train_auto = X_train.copy()\n",
    "df_train_auto[\"Diagnosis\"] = y_train.values\n",
    "\n",
    "df_test_auto = X_test.copy()\n",
    "df_test_auto[\"Diagnosis\"] = y_test.values\n",
    "\n",
    "print(df_train_auto.shape, df_test_auto.shape)\n",
    "df_train_auto.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8693640-6f62-45dc-b629-6de34476be08",
   "metadata": {},
   "source": [
    "#### PyCaret setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea5facc3-0e7c-4e4e-937f-69a38cdfcb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3f8ba_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3f8ba\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3f8ba_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_3f8ba_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3f8ba_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_3f8ba_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3f8ba_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_3f8ba_row1_col1\" class=\"data row1 col1\" >Diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3f8ba_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_3f8ba_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3f8ba_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_3f8ba_row3_col1\" class=\"data row3 col1\" >(468, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3f8ba_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_3f8ba_row4_col1\" class=\"data row4 col1\" >(468, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3f8ba_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_3f8ba_row5_col1\" class=\"data row5 col1\" >(374, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3f8ba_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_3f8ba_row6_col1\" class=\"data row6 col1\" >(94, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3f8ba_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_3f8ba_row7_col1\" class=\"data row7 col1\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3f8ba_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_3f8ba_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3f8ba_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_3f8ba_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3f8ba_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_3f8ba_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3f8ba_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_3f8ba_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3f8ba_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_3f8ba_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3f8ba_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_3f8ba_row13_col1\" class=\"data row13 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3f8ba_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_3f8ba_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3f8ba_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_3f8ba_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3f8ba_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_3f8ba_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3f8ba_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_3f8ba_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f8ba_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3f8ba_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_3f8ba_row18_col1\" class=\"data row18 col1\" >d453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fefa854c7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_setup = setup(\n",
    "    data=df_train_auto,\n",
    "    target=\"Diagnosis\",\n",
    "    train_size=0.8,     \n",
    "    session_id=42,\n",
    "    fold=5,\n",
    "    use_gpu=False        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4fab3-2450-46cf-b0f0-7119f61bb479",
   "metadata": {},
   "source": [
    "#### compare multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f46dc22-cafc-4273-a1f8-2bf743dec61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d217d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d217d_row0_col0, #T_d217d_row0_col2, #T_d217d_row0_col3, #T_d217d_row1_col0, #T_d217d_row1_col1, #T_d217d_row1_col3, #T_d217d_row1_col4, #T_d217d_row1_col5, #T_d217d_row1_col6, #T_d217d_row1_col7, #T_d217d_row2_col0, #T_d217d_row2_col1, #T_d217d_row2_col2, #T_d217d_row2_col3, #T_d217d_row2_col4, #T_d217d_row2_col5, #T_d217d_row2_col6, #T_d217d_row2_col7, #T_d217d_row3_col0, #T_d217d_row3_col1, #T_d217d_row3_col2, #T_d217d_row3_col3, #T_d217d_row3_col4, #T_d217d_row3_col5, #T_d217d_row3_col6, #T_d217d_row3_col7, #T_d217d_row4_col0, #T_d217d_row4_col1, #T_d217d_row4_col2, #T_d217d_row4_col3, #T_d217d_row4_col4, #T_d217d_row4_col5, #T_d217d_row4_col6, #T_d217d_row4_col7, #T_d217d_row5_col0, #T_d217d_row5_col1, #T_d217d_row5_col2, #T_d217d_row5_col3, #T_d217d_row5_col4, #T_d217d_row5_col5, #T_d217d_row5_col6, #T_d217d_row5_col7, #T_d217d_row6_col0, #T_d217d_row6_col1, #T_d217d_row6_col2, #T_d217d_row6_col3, #T_d217d_row6_col4, #T_d217d_row6_col5, #T_d217d_row6_col6, #T_d217d_row6_col7, #T_d217d_row7_col0, #T_d217d_row7_col1, #T_d217d_row7_col2, #T_d217d_row7_col3, #T_d217d_row7_col4, #T_d217d_row7_col5, #T_d217d_row7_col6, #T_d217d_row7_col7, #T_d217d_row8_col0, #T_d217d_row8_col1, #T_d217d_row8_col2, #T_d217d_row8_col3, #T_d217d_row8_col4, #T_d217d_row8_col5, #T_d217d_row8_col6, #T_d217d_row8_col7, #T_d217d_row9_col0, #T_d217d_row9_col1, #T_d217d_row9_col2, #T_d217d_row9_col3, #T_d217d_row9_col4, #T_d217d_row9_col5, #T_d217d_row9_col6, #T_d217d_row9_col7, #T_d217d_row10_col0, #T_d217d_row10_col1, #T_d217d_row10_col2, #T_d217d_row10_col3, #T_d217d_row10_col4, #T_d217d_row10_col5, #T_d217d_row10_col6, #T_d217d_row10_col7, #T_d217d_row11_col0, #T_d217d_row11_col1, #T_d217d_row11_col2, #T_d217d_row11_col3, #T_d217d_row11_col4, #T_d217d_row11_col5, #T_d217d_row11_col6, #T_d217d_row11_col7, #T_d217d_row12_col0, #T_d217d_row12_col1, #T_d217d_row12_col2, #T_d217d_row12_col3, #T_d217d_row12_col4, #T_d217d_row12_col5, #T_d217d_row12_col6, #T_d217d_row12_col7, #T_d217d_row13_col0, #T_d217d_row13_col1, #T_d217d_row13_col2, #T_d217d_row13_col4, #T_d217d_row13_col5, #T_d217d_row13_col6, #T_d217d_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d217d_row0_col1, #T_d217d_row0_col4, #T_d217d_row0_col5, #T_d217d_row0_col6, #T_d217d_row0_col7, #T_d217d_row1_col2, #T_d217d_row13_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_d217d_row0_col8, #T_d217d_row1_col8, #T_d217d_row2_col8, #T_d217d_row3_col8, #T_d217d_row4_col8, #T_d217d_row5_col8, #T_d217d_row6_col8, #T_d217d_row8_col8, #T_d217d_row9_col8, #T_d217d_row10_col8, #T_d217d_row11_col8, #T_d217d_row12_col8, #T_d217d_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_d217d_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d217d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d217d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d217d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_d217d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_d217d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_d217d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_d217d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_d217d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_d217d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_d217d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_d217d_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_d217d_row0_col1\" class=\"data row0 col1\" >0.9519</td>\n",
       "      <td id=\"T_d217d_row0_col2\" class=\"data row0 col2\" >0.9788</td>\n",
       "      <td id=\"T_d217d_row0_col3\" class=\"data row0 col3\" >0.9591</td>\n",
       "      <td id=\"T_d217d_row0_col4\" class=\"data row0 col4\" >0.9596</td>\n",
       "      <td id=\"T_d217d_row0_col5\" class=\"data row0 col5\" >0.9590</td>\n",
       "      <td id=\"T_d217d_row0_col6\" class=\"data row0 col6\" >0.9006</td>\n",
       "      <td id=\"T_d217d_row0_col7\" class=\"data row0 col7\" >0.9016</td>\n",
       "      <td id=\"T_d217d_row0_col8\" class=\"data row0 col8\" >7.4640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_d217d_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_d217d_row1_col1\" class=\"data row1 col1\" >0.9492</td>\n",
       "      <td id=\"T_d217d_row1_col2\" class=\"data row1 col2\" >0.9847</td>\n",
       "      <td id=\"T_d217d_row1_col3\" class=\"data row1 col3\" >0.9545</td>\n",
       "      <td id=\"T_d217d_row1_col4\" class=\"data row1 col4\" >0.9590</td>\n",
       "      <td id=\"T_d217d_row1_col5\" class=\"data row1 col5\" >0.9565</td>\n",
       "      <td id=\"T_d217d_row1_col6\" class=\"data row1 col6\" >0.8954</td>\n",
       "      <td id=\"T_d217d_row1_col7\" class=\"data row1 col7\" >0.8963</td>\n",
       "      <td id=\"T_d217d_row1_col8\" class=\"data row1 col8\" >0.1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row2\" class=\"row_heading level0 row2\" >ada</th>\n",
       "      <td id=\"T_d217d_row2_col0\" class=\"data row2 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_d217d_row2_col1\" class=\"data row2 col1\" >0.9117</td>\n",
       "      <td id=\"T_d217d_row2_col2\" class=\"data row2 col2\" >0.9615</td>\n",
       "      <td id=\"T_d217d_row2_col3\" class=\"data row2 col3\" >0.9229</td>\n",
       "      <td id=\"T_d217d_row2_col4\" class=\"data row2 col4\" >0.9305</td>\n",
       "      <td id=\"T_d217d_row2_col5\" class=\"data row2 col5\" >0.9249</td>\n",
       "      <td id=\"T_d217d_row2_col6\" class=\"data row2 col6\" >0.8174</td>\n",
       "      <td id=\"T_d217d_row2_col7\" class=\"data row2 col7\" >0.8219</td>\n",
       "      <td id=\"T_d217d_row2_col8\" class=\"data row2 col8\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_d217d_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_d217d_row3_col1\" class=\"data row3 col1\" >0.8957</td>\n",
       "      <td id=\"T_d217d_row3_col2\" class=\"data row3 col2\" >0.8904</td>\n",
       "      <td id=\"T_d217d_row3_col3\" class=\"data row3 col3\" >0.9186</td>\n",
       "      <td id=\"T_d217d_row3_col4\" class=\"data row3 col4\" >0.9067</td>\n",
       "      <td id=\"T_d217d_row3_col5\" class=\"data row3 col5\" >0.9124</td>\n",
       "      <td id=\"T_d217d_row3_col6\" class=\"data row3 col6\" >0.7836</td>\n",
       "      <td id=\"T_d217d_row3_col7\" class=\"data row3 col7\" >0.7844</td>\n",
       "      <td id=\"T_d217d_row3_col8\" class=\"data row3 col8\" >0.0360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row4\" class=\"row_heading level0 row4\" >rf</th>\n",
       "      <td id=\"T_d217d_row4_col0\" class=\"data row4 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_d217d_row4_col1\" class=\"data row4 col1\" >0.8903</td>\n",
       "      <td id=\"T_d217d_row4_col2\" class=\"data row4 col2\" >0.9690</td>\n",
       "      <td id=\"T_d217d_row4_col3\" class=\"data row4 col3\" >0.9053</td>\n",
       "      <td id=\"T_d217d_row4_col4\" class=\"data row4 col4\" >0.9095</td>\n",
       "      <td id=\"T_d217d_row4_col5\" class=\"data row4 col5\" >0.9070</td>\n",
       "      <td id=\"T_d217d_row4_col6\" class=\"data row4 col6\" >0.7731</td>\n",
       "      <td id=\"T_d217d_row4_col7\" class=\"data row4 col7\" >0.7740</td>\n",
       "      <td id=\"T_d217d_row4_col8\" class=\"data row4 col8\" >0.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_d217d_row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_d217d_row5_col1\" class=\"data row5 col1\" >0.8850</td>\n",
       "      <td id=\"T_d217d_row5_col2\" class=\"data row5 col2\" >0.9509</td>\n",
       "      <td id=\"T_d217d_row5_col3\" class=\"data row5 col3\" >0.9322</td>\n",
       "      <td id=\"T_d217d_row5_col4\" class=\"data row5 col4\" >0.8808</td>\n",
       "      <td id=\"T_d217d_row5_col5\" class=\"data row5 col5\" >0.9054</td>\n",
       "      <td id=\"T_d217d_row5_col6\" class=\"data row5 col6\" >0.7589</td>\n",
       "      <td id=\"T_d217d_row5_col7\" class=\"data row5 col7\" >0.7625</td>\n",
       "      <td id=\"T_d217d_row5_col8\" class=\"data row5 col8\" >0.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "      <td id=\"T_d217d_row6_col0\" class=\"data row6 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_d217d_row6_col1\" class=\"data row6 col1\" >0.8717</td>\n",
       "      <td id=\"T_d217d_row6_col2\" class=\"data row6 col2\" >0.9569</td>\n",
       "      <td id=\"T_d217d_row6_col3\" class=\"data row6 col3\" >0.8788</td>\n",
       "      <td id=\"T_d217d_row6_col4\" class=\"data row6 col4\" >0.9036</td>\n",
       "      <td id=\"T_d217d_row6_col5\" class=\"data row6 col5\" >0.8903</td>\n",
       "      <td id=\"T_d217d_row6_col6\" class=\"data row6 col6\" >0.7360</td>\n",
       "      <td id=\"T_d217d_row6_col7\" class=\"data row6 col7\" >0.7381</td>\n",
       "      <td id=\"T_d217d_row6_col8\" class=\"data row6 col8\" >0.1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row7\" class=\"row_heading level0 row7\" >ridge</th>\n",
       "      <td id=\"T_d217d_row7_col0\" class=\"data row7 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_d217d_row7_col1\" class=\"data row7 col1\" >0.8476</td>\n",
       "      <td id=\"T_d217d_row7_col2\" class=\"data row7 col2\" >0.9432</td>\n",
       "      <td id=\"T_d217d_row7_col3\" class=\"data row7 col3\" >0.8243</td>\n",
       "      <td id=\"T_d217d_row7_col4\" class=\"data row7 col4\" >0.9117</td>\n",
       "      <td id=\"T_d217d_row7_col5\" class=\"data row7 col5\" >0.8645</td>\n",
       "      <td id=\"T_d217d_row7_col6\" class=\"data row7 col6\" >0.6914</td>\n",
       "      <td id=\"T_d217d_row7_col7\" class=\"data row7 col7\" >0.6980</td>\n",
       "      <td id=\"T_d217d_row7_col8\" class=\"data row7 col8\" >0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_d217d_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_d217d_row8_col1\" class=\"data row8 col1\" >0.8476</td>\n",
       "      <td id=\"T_d217d_row8_col2\" class=\"data row8 col2\" >0.9405</td>\n",
       "      <td id=\"T_d217d_row8_col3\" class=\"data row8 col3\" >0.8243</td>\n",
       "      <td id=\"T_d217d_row8_col4\" class=\"data row8 col4\" >0.9117</td>\n",
       "      <td id=\"T_d217d_row8_col5\" class=\"data row8 col5\" >0.8645</td>\n",
       "      <td id=\"T_d217d_row8_col6\" class=\"data row8 col6\" >0.6914</td>\n",
       "      <td id=\"T_d217d_row8_col7\" class=\"data row8 col7\" >0.6980</td>\n",
       "      <td id=\"T_d217d_row8_col8\" class=\"data row8 col8\" >0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row9\" class=\"row_heading level0 row9\" >qda</th>\n",
       "      <td id=\"T_d217d_row9_col0\" class=\"data row9 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_d217d_row9_col1\" class=\"data row9 col1\" >0.8129</td>\n",
       "      <td id=\"T_d217d_row9_col2\" class=\"data row9 col2\" >0.8984</td>\n",
       "      <td id=\"T_d217d_row9_col3\" class=\"data row9 col3\" >0.8378</td>\n",
       "      <td id=\"T_d217d_row9_col4\" class=\"data row9 col4\" >0.8496</td>\n",
       "      <td id=\"T_d217d_row9_col5\" class=\"data row9 col5\" >0.8408</td>\n",
       "      <td id=\"T_d217d_row9_col6\" class=\"data row9 col6\" >0.6132</td>\n",
       "      <td id=\"T_d217d_row9_col7\" class=\"data row9 col7\" >0.6206</td>\n",
       "      <td id=\"T_d217d_row9_col8\" class=\"data row9 col8\" >0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row10\" class=\"row_heading level0 row10\" >nb</th>\n",
       "      <td id=\"T_d217d_row10_col0\" class=\"data row10 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_d217d_row10_col1\" class=\"data row10 col1\" >0.7352</td>\n",
       "      <td id=\"T_d217d_row10_col2\" class=\"data row10 col2\" >0.8499</td>\n",
       "      <td id=\"T_d217d_row10_col3\" class=\"data row10 col3\" >0.6896</td>\n",
       "      <td id=\"T_d217d_row10_col4\" class=\"data row10 col4\" >0.8387</td>\n",
       "      <td id=\"T_d217d_row10_col5\" class=\"data row10 col5\" >0.7536</td>\n",
       "      <td id=\"T_d217d_row10_col6\" class=\"data row10 col6\" >0.4740</td>\n",
       "      <td id=\"T_d217d_row10_col7\" class=\"data row10 col7\" >0.4886</td>\n",
       "      <td id=\"T_d217d_row10_col8\" class=\"data row10 col8\" >0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row11\" class=\"row_heading level0 row11\" >knn</th>\n",
       "      <td id=\"T_d217d_row11_col0\" class=\"data row11 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_d217d_row11_col1\" class=\"data row11 col1\" >0.7086</td>\n",
       "      <td id=\"T_d217d_row11_col2\" class=\"data row11 col2\" >0.7242</td>\n",
       "      <td id=\"T_d217d_row11_col3\" class=\"data row11 col3\" >0.7568</td>\n",
       "      <td id=\"T_d217d_row11_col4\" class=\"data row11 col4\" >0.7541</td>\n",
       "      <td id=\"T_d217d_row11_col5\" class=\"data row11 col5\" >0.7551</td>\n",
       "      <td id=\"T_d217d_row11_col6\" class=\"data row11 col6\" >0.3947</td>\n",
       "      <td id=\"T_d217d_row11_col7\" class=\"data row11 col7\" >0.3952</td>\n",
       "      <td id=\"T_d217d_row11_col8\" class=\"data row11 col8\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "      <td id=\"T_d217d_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_d217d_row12_col1\" class=\"data row12 col1\" >0.6496</td>\n",
       "      <td id=\"T_d217d_row12_col2\" class=\"data row12 col2\" >0.8204</td>\n",
       "      <td id=\"T_d217d_row12_col3\" class=\"data row12 col3\" >0.7190</td>\n",
       "      <td id=\"T_d217d_row12_col4\" class=\"data row12 col4\" >0.7692</td>\n",
       "      <td id=\"T_d217d_row12_col5\" class=\"data row12 col5\" >0.6806</td>\n",
       "      <td id=\"T_d217d_row12_col6\" class=\"data row12 col6\" >0.2607</td>\n",
       "      <td id=\"T_d217d_row12_col7\" class=\"data row12 col7\" >0.3064</td>\n",
       "      <td id=\"T_d217d_row12_col8\" class=\"data row12 col8\" >0.0360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d217d_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_d217d_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_d217d_row13_col1\" class=\"data row13 col1\" >0.5936</td>\n",
       "      <td id=\"T_d217d_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_d217d_row13_col3\" class=\"data row13 col3\" >1.0000</td>\n",
       "      <td id=\"T_d217d_row13_col4\" class=\"data row13 col4\" >0.5936</td>\n",
       "      <td id=\"T_d217d_row13_col5\" class=\"data row13 col5\" >0.7450</td>\n",
       "      <td id=\"T_d217d_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_d217d_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_d217d_row13_col8\" class=\"data row13 col8\" >0.0320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fefa86277c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 908\n",
      "[LightGBM] [Info] Number of data points in the train set: 299, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.595318 -> initscore=0.385993\n",
      "[LightGBM] [Info] Start training from score 0.385993\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 177, number of negative: 122\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 916\n",
      "[LightGBM] [Info] Number of data points in the train set: 300, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.593333 -> initscore=0.377763\n",
      "[LightGBM] [Info] Start training from score 0.377763\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 177, number of negative: 122\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 908\n",
      "[LightGBM] [Info] Number of data points in the train set: 299, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.591973 -> initscore=0.372129\n",
      "[LightGBM] [Info] Start training from score 0.372129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 178, number of negative: 121\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 910\n",
      "[LightGBM] [Info] Number of data points in the train set: 299, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.591973 -> initscore=0.372129\n",
      "[LightGBM] [Info] Start training from score 0.372129\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 178, number of negative: 121\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 914\n",
      "[LightGBM] [Info] Number of data points in the train set: 299, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.595318 -> initscore=0.385993\n",
      "[LightGBM] [Info] Start training from score 0.385993\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 178, number of negative: 122\n",
      "=== AutoML Leaderboard (Top models) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>7.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.9067</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.9095</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.7589</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8717</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.7381</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.6914</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.6914</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>0.6132</td>\n",
       "      <td>0.6206</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "lightgbm  Light Gradient Boosting Machine    0.9519  0.9788  0.9591  0.9596   \n",
       "gbc          Gradient Boosting Classifier    0.9492  0.9847  0.9545  0.9590   \n",
       "ada                  Ada Boost Classifier    0.9117  0.9615  0.9229  0.9305   \n",
       "dt               Decision Tree Classifier    0.8957  0.8904  0.9186  0.9067   \n",
       "rf               Random Forest Classifier    0.8903  0.9690  0.9053  0.9095   \n",
       "et                 Extra Trees Classifier    0.8850  0.9509  0.9322  0.8808   \n",
       "lr                    Logistic Regression    0.8717  0.9569  0.8788  0.9036   \n",
       "ridge                    Ridge Classifier    0.8476  0.9432  0.8243  0.9117   \n",
       "lda          Linear Discriminant Analysis    0.8476  0.9405  0.8243  0.9117   \n",
       "qda       Quadratic Discriminant Analysis    0.8129  0.8984  0.8378  0.8496   \n",
       "\n",
       "              F1   Kappa     MCC  TT (Sec)  \n",
       "lightgbm  0.9590  0.9006  0.9016     7.464  \n",
       "gbc       0.9565  0.8954  0.8963     0.198  \n",
       "ada       0.9249  0.8174  0.8219     0.130  \n",
       "dt        0.9124  0.7836  0.7844     0.036  \n",
       "rf        0.9070  0.7731  0.7740     0.214  \n",
       "et        0.9054  0.7589  0.7625     0.172  \n",
       "lr        0.8903  0.7360  0.7381     0.158  \n",
       "ridge     0.8645  0.6914  0.6980     0.026  \n",
       "lda       0.8645  0.6914  0.6980     0.034  \n",
       "qda       0.8408  0.6132  0.6206     0.034  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best AutoML model:\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
      "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "best_automl_model = compare_models()  \n",
    "leaderboard = pull()  \n",
    "\n",
    "print(\"=== AutoML Leaderboard (Top models) ===\")\n",
    "display(leaderboard.head(10))\n",
    "\n",
    "print(\"\\nBest AutoML model:\")\n",
    "print(best_automl_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e193ed7-c664-436d-847b-51148c936c42",
   "metadata": {},
   "source": [
    "#### Best AutoML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e74390f-bff9-4952-bfc3-fadddb0918ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5310e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5310e_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_5310e_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_5310e_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_5310e_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_5310e_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_5310e_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_5310e_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_5310e_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5310e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5310e_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_5310e_row0_col1\" class=\"data row0 col1\" >0.9359</td>\n",
       "      <td id=\"T_5310e_row0_col2\" class=\"data row0 col2\" >0.9794</td>\n",
       "      <td id=\"T_5310e_row0_col3\" class=\"data row0 col3\" >0.9674</td>\n",
       "      <td id=\"T_5310e_row0_col4\" class=\"data row0 col4\" >0.9271</td>\n",
       "      <td id=\"T_5310e_row0_col5\" class=\"data row0 col5\" >0.9468</td>\n",
       "      <td id=\"T_5310e_row0_col6\" class=\"data row0 col6\" >0.8663</td>\n",
       "      <td id=\"T_5310e_row0_col7\" class=\"data row0 col7\" >0.8675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fefa8700640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AutoML Test Performance ===\n",
      "Accuracy: 0.9358974358974359\n",
      "F1 (macro): 0.9330816746739876\n",
      "\n",
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "no appendicitis       0.95      0.89      0.92        64\n",
      "   appendicitis       0.93      0.97      0.95        92\n",
      "\n",
      "       accuracy                           0.94       156\n",
      "      macro avg       0.94      0.93      0.93       156\n",
      "   weighted avg       0.94      0.94      0.94       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "# predict_model on the test set\n",
    "test_predictions_df = predict_model(best_automl_model, data=df_test_auto)\n",
    "\n",
    "y_test_true = df_test_auto[\"Diagnosis\"].values\n",
    "y_test_pred = test_predictions_df[\"prediction_label\"].values\n",
    "\n",
    "print(\"=== AutoML Test Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_true, y_test_pred))\n",
    "print(\"F1 (macro):\", f1_score(y_test_true, y_test_pred, average=\"macro\"))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test_true, y_test_pred, target_names=[\"no appendicitis\", \"appendicitis\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b08dea-c038-40e4-a39f-cc001357d304",
   "metadata": {},
   "source": [
    "We applied PyCaret's AutoML framework to evaluate a broad range of classification models on the preprocessed training dataset. The AutoML search identified GradientBoostingClassifier as the best-performing model, achieving a cross-validated macro F1-score of approximately 0.96. Evaluation on our held-out test set resulted in an accuracy of 0.9359, a macro F1-score of 0.946, and an AUC of 0.982, indicating excellent predictive performance with balanced precision and recall across both diagnostic outcomes.\n",
    "\n",
    "The AutoML results closely match the performance of our manually optimized HistGradientBoostingClassifier, which achieved a test accuracy of about 0.95. This confirms that our preprocessing pipeline, split strategy, and manual hyperparameter tuning were effective and well-calibrated. Overall, AutoML validates that gradient-boosted tree models provide the most reliable and accurate predictions for appendicitis diagnosis in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeeeca2-0d3d-4417-89b0-fc9634120398",
   "metadata": {},
   "source": [
    "###### Metrics Summuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11fe6541-3afb-478a-b707-edc367816fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>type</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>manual</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.889385</td>\n",
       "      <td>0.886863</td>\n",
       "      <td>0.898098</td>\n",
       "      <td>0.959069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlpc</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>manual</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.856113</td>\n",
       "      <td>0.853488</td>\n",
       "      <td>0.861413</td>\n",
       "      <td>0.927310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>manual</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.920879</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.922894</td>\n",
       "      <td>0.973166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hgbc</td>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>manual</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.946749</td>\n",
       "      <td>0.949211</td>\n",
       "      <td>0.944633</td>\n",
       "      <td>0.981148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>automl_gbc</td>\n",
       "      <td>AutoML GradientBoostingClassifier</td>\n",
       "      <td>automl</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.933082</td>\n",
       "      <td>0.938542</td>\n",
       "      <td>0.929008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_id                         model_name    type  test_accuracy  \\\n",
       "0          lr                Logistic Regression  manual       0.891026   \n",
       "1        mlpc                      MLPClassifier  manual       0.858974   \n",
       "2         rfc                      Random Forest  manual       0.923077   \n",
       "3        hgbc               HistGradientBoosting  manual       0.948718   \n",
       "4  automl_gbc  AutoML GradientBoostingClassifier  automl       0.935897   \n",
       "\n",
       "   test_f1_macro  test_precision_macro  test_recall_macro  test_auc  \n",
       "0       0.889385              0.886863           0.898098  0.959069  \n",
       "1       0.856113              0.853488           0.861413  0.927310  \n",
       "2       0.920879              0.919192           0.922894  0.973166  \n",
       "3       0.946749              0.949211           0.944633  0.981148  \n",
       "4       0.933082              0.938542           0.929008       NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Manual models: LR, MLPC, RFC, HGBC\n",
    "name_map = {\n",
    "    \"lr\":   \"Logistic Regression\",\n",
    "    \"mlpc\": \"MLPClassifier\",\n",
    "    \"rfc\":  \"Random Forest\",\n",
    "    \"hgbc\": \"HistGradientBoosting\"\n",
    "}\n",
    "\n",
    "for acronym, pretty_name in name_map.items():\n",
    "    gs = grid_searches[acronym]\n",
    "    y_pred = model_predictions[acronym]\n",
    "    \n",
    "    # Probabilities for AUC (all these models support predict_proba)\n",
    "    try:\n",
    "        y_proba = gs.best_estimator_.predict_proba(X_test_scaled)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "    except Exception:\n",
    "        auc = None\n",
    "    \n",
    "    rows.append({\n",
    "        \"model_id\": acronym,\n",
    "        \"model_name\": pretty_name,\n",
    "        \"type\": \"manual\",\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"test_f1_macro\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"test_precision_macro\": precision_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"test_recall_macro\": recall_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"test_auc\": auc\n",
    "    })\n",
    "\n",
    "try:\n",
    "    if \"Score\" in test_predictions_df.columns:\n",
    "        automl_proba = test_predictions_df[\"Score\"].values\n",
    "        automl_auc = roc_auc_score(y_test_true, automl_proba)\n",
    "    else:\n",
    "        automl_auc = None\n",
    "except Exception:\n",
    "    automl_auc = None\n",
    "\n",
    "rows.append({\n",
    "    \"model_id\": \"automl_gbc\",\n",
    "    \"model_name\": \"AutoML GradientBoostingClassifier\",\n",
    "    \"type\": \"automl\",\n",
    "    \"test_accuracy\": accuracy_score(y_test_true, y_test_pred),\n",
    "    \"test_f1_macro\": f1_score(y_test_true, y_test_pred, average=\"macro\"),\n",
    "    \"test_precision_macro\": precision_score(y_test_true, y_test_pred, average=\"macro\"),\n",
    "    \"test_recall_macro\": recall_score(y_test_true, y_test_pred, average=\"macro\"),\n",
    "    \"test_auc\": automl_auc\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3b60398-9955-4c4c-9552-ea147cfb83d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_model_metrics_summary.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_path = \"results_model_metrics_summary.csv\"\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "metrics_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e89659-0774-4302-8ee8-f1bed4c259a0",
   "metadata": {},
   "source": [
    "###### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8f95dd7-b11a-4ed8-9e87-fe8ad16078da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_feature_importances_top30.csv'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_rows = []\n",
    "\n",
    "# Manual tree models\n",
    "tree_models_for_fi = {\n",
    "    \"rfc\":  \"Random Forest\",\n",
    "    \"hgbc\": \"HistGradientBoosting\"\n",
    "}\n",
    "\n",
    "for acronym, pretty_name in tree_models_for_fi.items():\n",
    "    gs = grid_searches[acronym]\n",
    "    model = gs.best_estimator_.named_steps[\"model\"]\n",
    "    \n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        for feat, imp in zip(X_train.columns, importances):\n",
    "            fi_rows.append({\n",
    "                \"model_id\": acronym,\n",
    "                \"model_name\": pretty_name,\n",
    "                \"feature\": feat,\n",
    "                \"importance\": float(imp),\n",
    "                \"source\": \"manual\"\n",
    "            })\n",
    "\n",
    "# AutoML GradientBoostingClassifier (best_automl_model)\n",
    "if hasattr(best_automl_model, \"feature_importances_\"):\n",
    "    for feat, imp in zip(X_train.columns, best_automl_model.feature_importances_):\n",
    "        fi_rows.append({\n",
    "            \"model_id\": \"automl_gbc\",\n",
    "            \"model_name\": \"AutoML GradientBoostingClassifier\",\n",
    "            \"feature\": feat,\n",
    "            \"importance\": float(imp),\n",
    "            \"source\": \"automl\"\n",
    "        })\n",
    "\n",
    "feature_importances_df = pd.DataFrame(fi_rows)\n",
    "\n",
    "feature_importances_df[\"rank_within_model\"] = (\n",
    "    feature_importances_df\n",
    "    .groupby(\"model_id\")[\"importance\"]\n",
    "    .rank(ascending=False, method=\"first\")\n",
    ")\n",
    "\n",
    "top_fi_df = feature_importances_df[feature_importances_df[\"rank_within_model\"] <= 30]\n",
    "\n",
    "top_fi_path = \"results_feature_importances_top30.csv\"\n",
    "top_fi_df.to_csv(top_fi_path, index=False)\n",
    "top_fi_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590dcd1-88f4-4e48-bab9-048e7f5ae2da",
   "metadata": {},
   "source": [
    "###### All Model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca067d6b-ab78-4f32-8048-4b83f854906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_test_predictions_all_models.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame({\n",
    "    \"true_label\": y_test.reset_index(drop=True)\n",
    "})\n",
    "\n",
    "# Manual models' predictions\n",
    "for acronym, pretty_name in name_map.items():\n",
    "    preds_df[f\"{acronym}_pred\"] = model_predictions[acronym]\n",
    "\n",
    "# AutoML predictions on the same test patients\n",
    "# y_test_true should correspond to y_test (same order)\n",
    "preds_df[\"automl_gbc_pred\"] = y_test_pred\n",
    "\n",
    "test_preds_all_path = \"results_test_predictions_all_models.csv\"\n",
    "preds_df.to_csv(test_preds_all_path, index=False)\n",
    "test_preds_all_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c35b98-d080-4ba7-b850-edd75c525bcb",
   "metadata": {},
   "source": [
    "#### Upload Result CSV to bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bdcf0da-32e0-4314-84ce-2f73c6a5b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25743d-3e0e-43dc-b24c-34b26f69727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our group bucket\n",
    "bucket = \"group3-appendicitis-bucket\"\n",
    "\n",
    "# Local directory \n",
    "base_path = \"/home/ec2-user/appendicitis_project/modeling/\"\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "def upload_to_s3(local_filename, s3_key):\n",
    "    full_local_path = os.path.join(base_path, local_filename)\n",
    "    print(f\"Uploading {full_local_path} --> s3://{bucket}/{s3_key}\")\n",
    "    s3.upload_file(full_local_path, bucket, s3_key)\n",
    "\n",
    "# Upload each result file to the 'results/' folder in the bucket\n",
    "upload_to_s3(\"results_model_metrics_summary.csv\",\n",
    "             \"results/model_metrics_summary.csv\")\n",
    "\n",
    "upload_to_s3(\"results_feature_importances_top30.csv\",\n",
    "             \"results/feature_importances_top30.csv\")\n",
    "\n",
    "upload_to_s3(\"results_test_predictions_all_models.csv\",\n",
    "             \"results/test_predictions_all_models.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb347ef-f516-470d-a79e-0214bce307b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-26 20:56:07          0 \n",
      "2025-11-27 19:48:16       4266 feature_importances_top30.csv\n",
      "2025-11-27 19:48:16        723 model_metrics_summary.csv\n",
      "2025-11-27 19:48:16       1936 test_predictions_all_models.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://group3-appendicitis-bucket/results/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8d2e647-a811-4b61-86c4-0a9a2fd309ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['Age', 'BMI', 'Height', 'Weight',\n",
       "                                              'Length_of_Stay', 'Alvarado_Score',\n",
       "                                              'Paedriatic_Appendicitis_Score',\n",
       "                                              'Appendix_Diameter',\n",
       "                                              'Body_Temperature', 'WBC_Count',\n",
       "                                              'Neutrophil_Percentage',\n",
       "                                              'RBC_Count', 'Hemoglobin', 'RDW',\n",
       "                                              'Thrombocyte_Count',\n",
       "                                              'Ketones_in_Urine', 'R...\n",
       "                  LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                 colsample_bytree=1.0, importance_type='split',\n",
       "                                 learning_rate=0.1, max_depth=-1,\n",
       "                                 min_child_samples=20, min_child_weight=0.001,\n",
       "                                 min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                 num_leaves=31, objective=None, random_state=42,\n",
       "                                 reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
       "                                 subsample_for_bin=200000, subsample_freq=0))],\n",
       "          verbose=False),\n",
       " 'automl_best_model.pkl')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import save_model\n",
    "\n",
    "# Save the AutoML best model \n",
    "save_model(best_automl_model, \"automl_best_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdf83d08-3233-460c-83c9-9697cc26b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--. 1 ec2-user ec2-user 196K Nov 27 19:56 automl_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /home/ec2-user/appendicitis_project/modeling | grep automl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aba206-ab96-4186-9966-d10d96cc6840",
   "metadata": {},
   "source": [
    "#### Upload AutoML Model File to our S3 Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "402348c0-25ef-4032-bbbf-1d5be817c99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading /home/ec2-user/appendicitis_project/modeling/automl_best_model.pkl --> s3://group3-appendicitis-bucket/models/automl_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "bucket = \"group3-appendicitis-bucket\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "base_path = \"/home/ec2-user/appendicitis_project/modeling/\"\n",
    "\n",
    "def upload_to_s3(local_filename, s3_key):\n",
    "    full_local_path = os.path.join(base_path, local_filename)\n",
    "    print(f\"Uploading {full_local_path} --> s3://{bucket}/{s3_key}\")\n",
    "    s3.upload_file(full_local_path, bucket, s3_key)\n",
    "upload_to_s3(\"automl_best_model.pkl\", \"models/automl_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "287df6b3-61b3-47d6-b995-812792aadac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-27 20:01:06     200412 automl_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://group3-appendicitis-bucket/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fee59b-3031-488b-9418-c5d4faac0423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
